# Data Science Portfolio

This repository contains the files for the Portfolio task

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

*Analysis of Cycling Data*

**Dataset Used**
1. The datasets used in this portfolio are Calga_RR_2016.gpx, Calga_RR_2019.gpx, Calga_TT_2016.gpx, and Calga_TT_2019.gpx.

**Analysis**
1. Extraction,read and named the datasets.
2. Calculations of the overall distances, average speeds and total time used for each ride.
3. Line graphs for speed range of each ride.
4. Scatter graph and bar graph for comparison of the average and maximum speed achieved in two time trails.
5. Calculations and bar graphs for average speed according to the elevation gain for each ride.
6. Finding te relationship between cadence, speed and development.
7. Obtain a new formula to calculate development based on cadence and speed.
8. Histogram and line graphs for development of each ride.

**Goal of this portfolio**
1. Analyze and observe the dataset
2. Provide visualization explanation and summary answers for the questions.

*Conclusion*

In this dataset, we observed and concluded that the average speed for 2016 rides were faster than 2019 rides. The total time used for each ride were slightly different. Riders in 2016 seems to have more to power to maintain their speed in every fields.


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

*Sport Vouchers Program Analysis*

**Dataset Used**
1. The datasets used in this portfolio are sportsvouchersclaimed.csv and ABS_SEIFA_LGA.csv.

**Analysis**
1. Exttraction, read and named the dataset.
2. Join both dataset to create a whole new dataset.
3. Group and describe the dataset according to LGA and sport.
4. Calculations and bar graph for both LGA and sport sorted dataset.
5. Group and display heatmap for 2 dimensional dataset which is the popularity of sport in different LGA.
6. Double y-axis graph to estimate the representation of the use of sport vouchers in each LGA.
7. Calculate the correlation between two dataset in term of the use of vouchers and SEIFA measures.
8. Heatmap for 2 dimensional dataset for different activities in Queensland according to the LGA.
9. Bar graph to visualize the application number for different fields.
10. Correlation calculation between SEIFA measures, LGA and application number.

**Goal of this portfolio**
1. Analyze and observe the dataset.
2. Provide visual solution to answer each given questions.

**Conclusion**

In a nutshell, there is no clear statistical relationshop between these two dataset. However, the popularity of sports were various according to different LGA. Australian rules and netball are the most preferable sports among other sports in New South Wales while Queensland's kids like rugby league and football more than other activities.


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

*Mobile Customer Churn*

**Dataset Used**
1. The datasets used in this portfolio are MobileCustomerChurn.csv and MobileChurnDataDictionary.csv.

**Analysis**
1. Extraction, read and named the dataset.
2. Description of the dataset.
3. Checking the dataset values that are unique and NaN.
4. Create a new dataset which consist of the important part of old dataset.
5. Drop some useless columns.
6. Replace and modify some of the values with rank.
7. Modify those Nan values in the dataset into 0. 
8. Modify the data type of the new dataset.
9. Create train and test dataset by spliting the new dataset.
10. Run the train and test dataset with logistic regression and prediction.
11. Calculate the accuracy score.
12. Visualize the confusion matrix.

**Goal of this portfolio**
1. Analyze and observe the dataset.
2. Create a prediction model for churn.

**Conclusion**

In conclusion, the prediction model for churn works with the accuracy score of 0.7. Churn is where a customer leave their mobile provider. We can use this model to calculate, estimate and predict the mobile customer churn with a successful rate of 70%.


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

*Taxation in Different Postcodes*

**Dataset Used**
1. The datasets used in this portfolio is ts17individual25countaveragemedianbypostcode.csv.

**Analysis**
1. Extraction,read and named the datasets.
2. NaN values checking.
3. Display and visualize each fields in line gaphs.
4. Table display for the lowest and highest results.
5. Build logistic regression model based on count net tax.
6. Test and train set spliting.
7. Calculation for correlation coeeficient.
8. Calculation for accuracy score.
9. Build logistic regression model based on average net tax.
10. Test and train set spliting.
11. Calculation for correlation coeeficient.
12. Calculation for accuracy score.

**Goal of this portfolio**
1. Analyze and observe the dataset.
2. Provide visualization explanation.
3. Compare different output to prove or reject assumption.

**Conclusion**

To summarise what I have learnt from our evaluation of the data set "Taxation based on postcodes" is that there is a very mixed basket of results and that there are some outliers that have a much higher average salary and wage and thus a higher amount of average tax paid by those outliers. From the first two plots, we can see that there is a very comparable difference between what people's average salaries are and the amount of tax that they pay. unsurprisingly the postcode with the highest salary is the one that is paying the most tax (postcode 3010) with an average salary of 141,262 dollars and an average tax of 61,126 dollars, but there are a lot of postcodes that earn a lot less and pay almost the same amount of tax as that of the highest-earning postcodes.
